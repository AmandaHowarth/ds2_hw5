---
title: "data science HW5"
author: "Amanda Howarth"
date: "5/9/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(mlbench)
library(caret)
library(e1071)
library(ISLR)
```

Create atraining set containing a random sample of 800 observations, and a test set containing theremaining observations.
```{r}
data(OJ)

set.seed(1)
rowTrain <- createDataPartition(y = OJ$Purchase,
                               p = 0.747,
                               list = FALSE)
```

# Using `caret`
# Question A 
Fit a support vector classifier (linear kernel) to the training data with Purchase as the response and the other variables as predictors.  What are the training and test error rates?

```{r}
ctrl <- trainControl(method = "cv")

set.seed(1)
svml.fit <- train(Purchase~., 
                  data = OJ[rowTrain,], 
                  method = "svmLinear2",
                  preProcess = c("center", "scale"),
                  tuneGrid = data.frame(cost = exp(seq(-8,0,len=20))),
                  trControl = ctrl)

ggplot(svml.fit, highlight = TRUE)
```
# using kernels

```{r}
svmr.grid <- expand.grid(C = exp(seq(-2,2,len=10)),
                         sigma = exp(seq(-7,-2,len=10)))
set.seed(1)             
svmr.fit <- train(Purchase~., OJ, 
                  subset = rowTrain,
                  method = "svmRadial",
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,
                  trControl = ctrl)

ggplot(svmr.fit, highlight = TRUE)

```

```{r}
resamp <- resamples(list(svmr = svmr.fit, svml = svml.fit))
bwplot(resamp)
summary(resamp)
```
Suppport vector classifier with linear boundary (SVML): 
TRAINING ERROR: 0.8262144

Support vector machine with radial kernel (SVMR): 
TRAINING ERROR: 0.8324795

The support vector machine with radial kernel model has better performance based on cross validation. However, both perform incredibly similarly. Ultimately, the best model appears to be SVMR.


We finally look at the test data performance.
```{r}

pred.svml <- predict(svml.fit, newdata = OJ[-rowTrain,])
pred.svmr <- predict(svmr.fit, newdata = OJ[-rowTrain,])

confusionMatrix(data = pred.svml, 
                reference = OJ$Purchase[-rowTrain])

confusionMatrix(data = pred.svmr, 
                reference = OJ$Purchase[-rowTrain])
```
Suppport vector classifier with linear boundary: 
TEST ERROR:  0.8519  

Support vector machine with radial kernel: 
TEST ERROR:  0.8481   



